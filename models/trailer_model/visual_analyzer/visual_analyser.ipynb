{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"visual_analyser.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XYwi6_2F22wO","colab_type":"text"},"source":["# Prediction based on Trailer"]},{"cell_type":"markdown","metadata":{"id":"Jtg5Vtg73BTe","colab_type":"text"},"source":["## Import"]},{"cell_type":"code","metadata":{"id":"JleKJBN04NbQ","colab_type":"code","colab":{}},"source":["import json\n","import os\n","import pickle\n","import urllib\n","import os\n","import numpy as np\n","import pandas as pd\n","\n","from bs4 import BeautifulSoup\n","\n","try:\n","    from google.colab import drive\n","    drive_dir = '/content/drive'\n","    drive.mount(drive_dir)\n","    root_dir = '/content/drive/My Drive/AML/'\n","    git_dir = root_dir+'Git/'\n","    COLAB_IN = True\n","except:\n","    COLAB_IN = False\n","\n","if COLAB_IN:\n","    os.chdir(\"drive/My Drive/AML/Git_lastClone/neural-network/trailer_model/visual_analyzer\")\n","    !pip install youtube_dl\n","    !pip install imdbpy\n","    !pip install bcolz\n","    \n","import keras\n","from keras.models import Sequential\n","import numpy as np\n","import tensorflow as tf\n","\n","import json\n","import functools\n","import itertools\n","import numpy\n","import operator\n","from keras.utils import to_categorical\n","import urllib.parse\n","import urllib.request\n","import requests\n","\n","import youtube_dl\n","\n","import imdb\n","from tqdm import tnrange, tqdm_notebook, tqdm\n","import sys\n","from bs4 import BeautifulSoup\n","\n","import cv2     # for capturing videos\n","import math   # for mathematical operations\n","import matplotlib.pyplot as plt    # for plotting the images\n","\n","import pandas as pd\n","from keras.preprocessing import image   # for preprocessing the images\n","import numpy as np    # for mathematical operations\n","from keras.utils import np_utils\n","from skimage.transform import resize   # for resizing images\n","import time\n","\n","\n","import os \n","import argparse\n","import time\n","from __future__ import print_function\n","import argparse\n","import cv2\n","import os \n","import PIL\n","from PIL import Image\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Convolution2D, MaxPooling2D\n","from keras.optimizers import Adadelta\n","from keras.utils import np_utils\n","from keras.regularizers import l2\n","import numpy as np\n","import pickle as cPickle \n","import numpy\n","import cv2\n","import scipy\n","import csv\n","import imutils\n","from skimage import io\n","import dlib\n","import json\n","import time\n","import pandas as pd \n","import glob\n","from IPython.display import Image\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N0r21aqP3Mct","colab_type":"text"},"source":["## Utility functions"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pVOn80fc7nWm","colab":{}},"source":["def urlopen(url, mobile = False):\n","    try:\n","        if mobile:\n","            urlheader =  {'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 5_0 like Mac OS X) AppleWebKit/534.46' ,\n","            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n","            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n","            'Accept-Encoding': 'none',\n","            'Accept-Language': 'en-US,en;q=0.8',\n","            'Connection': 'keep-alive'}\n","        else:\n","            urlheader = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \n","                          'AppleWebKit/537.11 (KHTML, like Gecko) '\n","                          'Chrome/23.0.1271.64 Safari/537.11',\n","            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n","            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n","            'Accept-Encoding': 'none',\n","            'Accept-Language': 'en-US,en;q=0.8',\n","            'Connection': 'keep-alive'\n","                        }\n","        #header2 = 'Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17'\n","        return urllib.request.urlopen(urllib.request.Request(url=url, data=None, headers=urlheader)).read().decode('utf-8')\n","    except HTTPError as e:\n","        if (_WARNINGS):\n","            time.sleep(5);\n","            warnings.warn(str(e))\n","            return urlopen(url)\n","        else:\n","            raise e"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2IHWe6UD2pbS"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FVtr2LQR2pDQ"},"source":["### Loader"]},{"cell_type":"code","metadata":{"id":"DL9AjkAt5x0H","colab_type":"code","colab":{}},"source":["class Entry:\n","  \n","  def __init__(self, **kwargs):\n","    self.movie_id = kwargs['movie_id']\n","    self.name = kwargs['name']\n","    self.revenue_opening = kwargs['revenue_opening']\n","    self.revenue_total = kwargs['revenue_total']\n","    \n","  def __repr__(self):\n","    return f'Name: {self.name}; movie ID: {self.movie_id}'\n","    \n","  def set_metadata(self, metadata_dict):\n","    self.year = metadata_dict['year']\n","    self.genres = metadata_dict['genres']\n","    self.actors = metadata_dict['actors']\n","    self.directors = metadata_dict['directors']\n","    self.creators = metadata_dict['creators']\n","    self.duration = metadata_dict['duration']\n","    \n","  def set_trailers(self, trailer_dict):\n","    self.imdb_trailer = trailer_dict['imdb_trailer']\n","    self.youtube_trailer = trailer_dict['youtube_trailer']\n","    \n","\n","class Dataset:\n","  \n","  def __init__(self, dataset_dir):\n","    self.basic_data = pd.read_csv(os.path.join(dataset_dir, 'Dataset.csv'))\n","    self.dataset_dir = dataset_dir\n","    \n","    self.entries = list()\n","    self.movie_indeces = dict()\n","    self._create_entries()\n","    \n","    self.Youtube_urlroot = \"https://www.youtube.com\"\n","    self.Imdb_urlroot = \"https://www.imdb.com\"\n","    \n","  def get_entry(self, movie_id):\n","    return self.entries[self.movie_indeces[movie_id]]\n","  \n","  def get_revenue(self, movie_id):\n","    tmp_df = self.basic_data[self.basic_data['movie_id'] == movie_id]\n","    return tmp_df['revenue_opening'].values[0]\n","  \n","  def load_metadata(self):\n","    with open(os.path.join(self.dataset_dir, 'metadata.data'), 'rb') as fr:\n","      metadata_dict = pickle.load(fr)\n","      \n","    for k, v in metadata_dict['global'].items():\n","      self.__dict__[k] = self._decompress_global_categorical(v)\n","      \n","    for movie_id, movie_metadata in metadata_dict['entries'].items():\n","      entry = self.entries[self.movie_indeces[movie_id]]\n","      entry.set_metadata(movie_metadata)\n","      \n","      # decompress categorical\n","      entry.actors = self._decompress_categorical(entry.actors, len(self.all_actors))\n","      entry.creators = self._decompress_categorical(entry.creators, len(self.all_creators))\n","      entry.directors = self._decompress_categorical(entry.directors, len(self.all_directors))\n","      entry.genres = self._decompress_categorical(entry.genres, len(self.all_genres))\n","    \n","  def load_trailers(self):\n","    with open(os.path.join(self.dataset_dir, 'trailers.data'), 'rb') as fr:\n","      trailers_dict = pickle.load(fr)\n","      \n","    for movie_id, trailers in trailers_dict.items():\n","      entry = self.entries[self.movie_indeces[movie_id]]\n","      entry.set_trailers(trailers)\n","  \n","  def GetTrailer(self, IMDbVideoUrl, YoutubeVideoUrl, trailers_dir, filename): # download trailer\n","        file_output = os.path.join(trailers_dir, filename+\".mp4\")\n","        !youtube-dl -f best --force-ipv4 --merge-output-format mp4 '$YoutubeVideoUrl' -o '$file_output' > /dev/null\n","            \n","  def _create_entries(self):\n","    for idx, [movie_id, name, rev_open, rev_total] in self.basic_data.iterrows():\n","      entry = Entry(movie_id=movie_id, name=name,\n","                   revenue_opening = rev_open,\n","                   revenue_total = rev_total)\n","      self.entries.append(entry)\n","      self.movie_indeces[movie_id] = idx\n","      \n","  def _compress_global_categorical(self, input_dict):\n","    output_dict = dict()\n","    for k, v in input_dict.items():\n","      output_dict[k] = np.argmax(v)\n","\n","    return output_dict\n","  \n","  def _decompress_global_categorical(self, input_dict):\n","    output_dict = dict()\n","    for k, v in input_dict.items():\n","      indicator = np.zeros(len(input_dict))\n","      indicator[v] = 1\n","      output_dict[k] = indicator\n","      \n","    return output_dict\n","  \n","  def _compress_categorical(self, arr):\n","    dct = dict()\n","    for idx, val in enumerate(arr):\n","      if val > 0:\n","        dct[idx] = val\n","\n","    return dct\n","  \n","  def _decompress_categorical(self, arr, total_len):\n","    indicator = np.zeros(total_len)\n","    for idx, val in arr.items():\n","      indicator[idx] = val\n","    \n","    return indicator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n-uOnXsQDzIh","colab_type":"code","colab":{}},"source":["movies = Dataset(dataset_dir = '../../dataset/')\n","\n","movies.load_trailers()\n","movies.load_metadata()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9JOgV8CWys3X","colab_type":"text"},"source":["##Feature Extractor"]},{"cell_type":"code","metadata":{"id":"urNyuYLhJfYw","colab_type":"code","colab":{}},"source":["\n","class VisualFeatureExtractor:\n","    def __init__(self, model_dir):\n","        self.emotionPredictionModel(model_dir)\n","        self.detector = dlib.get_frontal_face_detector()\n","    \n","    \n","    # ****** image processing ****** \"\"\"\n","    def Flip(self, data):\n","        dataFlipped = data[..., ::-1].reshape(2304).tolist()\n","        return dataFlipped\n","\n","    def Roated15Left(self, data):\n","        num_rows, num_cols = data.shape[:2]\n","        rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), 20, 1)\n","        img_rotation = cv2.warpAffine(data, rotation_matrix, (num_cols, num_rows))\n","        return img_rotation.reshape(2304).tolist()\n","    \n","    def Roated15Right(self, data):\n","        num_rows, num_cols = data.shape[:2]\n","        rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), -20, 1)\n","        img_rotation = cv2.warpAffine(data, rotation_matrix, (num_cols, num_rows))\n","        return img_rotation.reshape(2304).tolist()\n","\n","    def shiftedUp20(self, data):\n","        translated = imutils.translate(data, 0, -5)\n","        translated2 = translated.reshape(2304).tolist()\n","        return translated2\n","    \n","    def shiftedDown20(self, data):\n","        translated = imutils.translate(data, 0, 5)\n","        translated2 = translated.reshape(2304).tolist()\n","        return translated2\n","\n","    def shiftedLeft20(self, data):\n","        translated = imutils.translate(data, -5, 0)\n","        translated2 = translated.reshape(2304).tolist()\n","        return translated2\n","    \n","    def shiftedRight20(self, data):\n","        translated = imutils.translate(data, 5, 0)\n","        translated2 = translated.reshape(2304).tolist()\n","        return translated2\n","\n","    def flatten_matrix(self, matrix):\n","        vector = matrix.flatten(1)\n","        vector = vector.reshape(1, len(vector))\n","        return vector\n","    \n","    def zca_whitening(self, inputs):\n","        sigma = np.dot(inputs, inputs.T)/inputs.shape[1] #Correlation matrix\n","        U,S,V = np.linalg.svd(sigma) #Singular Value Decomposition\n","        epsilon = 0.1                #Whitening constant, it prevents division by zero\n","        ZCAMatrix = np.dot(np.dot(U, np.diag(1.0/np.sqrt(np.diag(S) + epsilon))), U.T)                     #ZCA Whitening matrix\n","        return np.dot(ZCAMatrix, inputs)   #Data whitening\n","    \n","    def global_contrast_normalize(self, X, scale=1., subtract_mean=True, use_std=True, sqrt_bias=10, min_divisor=1e-8):\n","        assert X.ndim == 2, \"X.ndim must be 2\"\n","        scale = float(scale)\n","        assert scale >= min_divisor\n","        mean = X.mean(axis=1)\n","        if subtract_mean:\n","            X = X - mean[:, numpy.newaxis]  # Makes a copy.\n","        else:\n","            X = X.copy()\n","\n","        if use_std:\n","            ddof = 1\n","            if X.shape[1] == 1:\n","                ddof = 0\n","\n","            normalizers = numpy.sqrt(sqrt_bias + X.var(axis=1, ddof=ddof)) / scale\n","        else:\n","            normalizers = numpy.sqrt(sqrt_bias + (X ** 2).sum(axis=1)) / scale\n","\n","        # Don't normalize by anything too small.\n","        normalizers[normalizers < min_divisor] = 1.\n","\n","        X /= normalizers[:, numpy.newaxis]  # Does not make a copy.\n","        return X\n","    \n","    def ZeroCenter(self, data):\n","        data = data - numpy.mean(data,axis=0)\n","        return data\n","\n","    def normalize(self, arr):\n","        for i in range(3):\n","            minval = arr[...,i].min()\n","            maxval = arr[...,i].max()\n","            if minval != maxval:\n","                arr[...,i] -= minval\n","                arr[...,i] *= (255.0/(maxval-minval))\n","        return arr\n","\n","    def ConvertToArrayandReshape(self, List):\n","        numpyarray = numpy.asarray(List)\n","        numpyarray = numpyarray.reshape(1,48,48)\n","        numpyarray = numpyarray.reshape(1, 48, 48,1)\n","        numpyarray = numpyarray.astype('float32')\n","        return numpyarray\n","    \n","    def imagePreprocessing(self, crop2):\n","        data2 = self.ZeroCenter(crop2)\n","        data3 = self.zca_whitening(self.flatten_matrix(data2)).reshape(48,48)\n","        data4 = self.global_contrast_normalize(data3)\n","        data5 = numpy.rot90(data4,3)\n","        return data5\n","    \n","    #calculate brightness\n","    def getBrightness(self, frame):   \n","        import cv2\n","        #convert image to HSV format\n","        HSV=cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)   \n","        #calculate the brightness (mean of the V-Channel)\n","        brightness = np.mean(HSV[:,:,2].flatten())\n","        return brightness\n","\n","\n","    #calculate sharpness\n","    def getSharpness(self, frame):\n","        #install cpbd library and its dependies \n","        !pip install cpbd\n","        !pip install scipy==4.3.0\n","        !pip install Pillow\n","\n","        import cv2\n","        import cpbd\n","        from scipy import ndimage\n","        import matplotlib.pyplot as plt\n","        #estimate sharpness\n","        sharpness=cpbd.compute(frame)\n","        return sharpness\n","    \n","     # ****** Emotion prediction (NN) ****** \"\"\"\n","    def emotionPredictionModel(self, model_dir):\n","        img_rows, img_cols = 48, 48\n","        # the CIFAR10 images are RGB\n","        img_channels = 1\n","\n","        model = Sequential()\n","        model.add(Convolution2D(64, (5, 5), border_mode='valid',\n","                                input_shape=(img_rows, img_cols,1)))\n","        model.add(keras.layers.advanced_activations.PReLU(alpha_initializer='zero', weights=None))\n","        model.add(keras.layers.convolutional.ZeroPadding2D(padding=(2, 2), data_format=\"channels_first\"))\n","        model.add(MaxPooling2D(pool_size=(5, 5),strides=(2, 2)))\n","\n","        model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), data_format=\"channels_first\")) \n","        model.add(Convolution2D(64, (3, 3)))\n","        model.add(keras.layers.advanced_activations.PReLU(alpha_initializer='zero', weights=None))\n","        model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), data_format=\"channels_first\")) \n","        model.add(Convolution2D(64, (3, 3)))\n","        model.add(keras.layers.advanced_activations.PReLU(alpha_initializer='zero', weights=None))\n","        model.add(keras.layers.convolutional.AveragePooling2D(pool_size=(3, 3),strides=(2, 2)))\n","\n","        model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), data_format=\"channels_first\"))\n","        model.add(Convolution2D(128, (3, 3)))\n","        model.add(keras.layers.advanced_activations.PReLU(alpha_initializer='zero', weights=None))\n","        model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), data_format=\"channels_first\"))\n","        model.add(Convolution2D(128, (3, 3)))\n","        model.add(keras.layers.advanced_activations.PReLU(alpha_initializer='zero', weights=None))\n","\n","        model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), data_format=\"channels_first\"))\n","        model.add(keras.layers.convolutional.AveragePooling2D(pool_size=(3, 3),strides=(2, 2)))\n","\n","\n","        model.add(Flatten())\n","        model.add(Dense(1024))\n","        model.add(keras.layers.advanced_activations.PReLU(alpha_initializer='zero', weights=None))\n","        model.add(Dropout(0.2))\n","        model.add(Dense(1024))\n","        model.add(keras.layers.advanced_activations.PReLU(alpha_initializer='zero', weights=None))\n","        model.add(Dropout(0.2))\n","\n","\n","        model.add(Dense(7))\n","\n","\n","        model.add(Activation('softmax'))\n","\n","\n","        ada = Adadelta(lr=0.1, rho=0.95, epsilon=1e-08)\n","        model.compile(loss='categorical_crossentropy',\n","                      optimizer=ada,\n","                      metrics=['accuracy'])\n","\n","\n","        filepath=os.path.join(model_dir, \"Model.120-0.6343.hdf5\")\n","        print(filepath)\n","        model.load_weights(filepath)\n","        self.model = model\n","        \n","    def emotionPrediction(self, data5):\n","        Train_x_Init = self.ConvertToArrayandReshape(data5)\n","        Train_x_Flip  = self.ConvertToArrayandReshape(self.Flip(data5))\n","        Train_x_Rotleft = self.ConvertToArrayandReshape(self.Roated15Left(data5))\n","        Train_x_Rotright = self.ConvertToArrayandReshape(self.Roated15Right(data5))\n","        Train_x_ShiftedUp = self.ConvertToArrayandReshape(self.shiftedUp20(data5))\n","        Train_x_ShiftedDown = self.ConvertToArrayandReshape(self.shiftedDown20(data5))\n","        Train_x_ShiftedLeft = self.ConvertToArrayandReshape(self.shiftedLeft20(data5))\n","        Train_x_ShiftedRight = self.ConvertToArrayandReshape(self.shiftedRight20(data5))\n","        a= np.array([  self.model.predict_proba(Train_x_Init, verbose=0)[0]])\n","        return a.mean(axis=0)\n","    \n","    # ****** Face detection ****** \"\"\"\n","    def faceDetection(self, img):#extract faces\n","        grayimg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","        dets, scores, idx= self.detector.run(grayimg,1)\n","        imgWithRect = img#cv2.imread(imagepath)\n","        ListOfFaces = []\n","        FaceWriteList = []\n","        temp=0\n","        for rectangle in dets:\n","            if(scores[temp]>0.2):\n","                #print(\"face detected\")\n","                left = rectangle.left()\n","                top = rectangle.top()\n","                right = rectangle.right()\n","                bottom = rectangle.bottom()\n","                if top<0:\n","                    offset = 0-top\n","                    top = 0\n","                    bottom = bottom+offset\n","                if left<0:\n","                    offset = 0 -left\n","                    left =0\n","                    right = right+offset\n","                cv2.rectangle(imgWithRect,(left,top),(right,bottom),(255,255,255),2)\n","                crop = grayimg[top:bottom, left:right]\n","                colored_crop=img[top:bottom, left:right]\n","                crop2 = cv2.resize(crop, (48, 48)) \n","                data = self.imagePreprocessing(crop2)\n","                ListOfFaces.append(data)\n","                FaceWriteList.append(colored_crop)\n","            temp+=1\n","\n","        return ListOfFaces, FaceWriteList\n","    \n","    \n","    # ****** extraction ****** \"\"\"\n","    def extract(self, file, resolution):\n","        \n","        import csv\n","        #fps\n","        fps=1\n","        #read the video from the file\n","        cap = cv2.VideoCapture(file)\n","        cap.set(cv2.CAP_PROP_FPS, 15)\n","        n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        # to add to csv\n","        video_fps = cap.get(cv2.CAP_PROP_FPS)\n","        width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float\n","        height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT) # float\n","        try:\n","            duration = n_frames/video_fps\n","        except:\n","            duration=0.0\n","        print('duration=',duration)\n","        #initialization\n","        colors_R = []\n","        colors_G = []\n","        colors_B = []\n","        brightness=[]\n","        sharpness=[]\n","        Anger=[0.0]\n","        Disgust=[0.0]\n","        Fear=[0.0]\n","        Happy=[0.0]\n","        Sad=[0.0]\n","        Surprise=[0.0]\n","        Neutral=[0.0]\n","        \n","        ret = True\n","        frame_index = -1\n","        count=0\n","        \n","        pbar2 = tqdm_notebook(total=n_frames)\n","        if duration<=600:\n","            while ret:\n","                count=count+1\n","                #next frame\n","                frame_index = frame_index + 1   \n","                #read the frame\n","                ret, frame = cap.read()\n","\n","\n","                if video_fps > fps and frame_index % int(video_fps / fps) != 0:\n","                    continue\n","\n","                if ret:         \n","                    #extract colors\n","                    colors_R.append(np.mean(frame[:,:,0].flatten()))\n","                    colors_G.append(np.mean(frame[:,:,1].flatten()))\n","                    colors_B.append(np.mean(frame[:,:,2].flatten()))\n","                    #extract brightness\n","                    brightness.append(self.getBrightness(frame))\n","                    #extract sharpness\n","                    #sharpness.append(self.getSharpness(frame))\n","                    #integrate the code of syrine to extract emotion\n","                    if count%10==0:\n","\n","                        ListOfFaces,FaceWriteList = self.faceDetection(frame)\n","                        temp_list=[]\n","                        for face, coors in zip(ListOfFaces, FaceWriteList):\n","                            result = self.emotionPrediction(face)\n","                            temp_list.append(result)\n","                        for y in temp_list:\n","                            Anger.append(y[0])\n","                            Disgust.append(y[1])\n","                            Fear.append(y[2])\n","                            Happy.append(y[3])\n","                            Sad.append(y[4])\n","                            Surprise.append(y[5])\n","                            Neutral.append(y[6])\n","                pbar2.update(frame_index - pbar2.n)\n","        \n","            \n","            \n","            mean_Anger=np.mean(np.array(Anger))\n","            mean_Disgust=np.mean(np.array(Disgust))\n","            mean_Fear=np.mean(np.array(Fear))\n","            mean_Happy=np.mean(np.array(Happy))\n","            mean_Sad=np.mean(np.array(Sad))\n","            mean_Surprise=np.mean(np.array(Surprise))\n","            mean_Neutral=np.mean(np.array(Neutral))\n","\n","            var_Anger=np.var(np.array(Anger))\n","            var_Disgust=np.var(np.array(Disgust))\n","            var_Fear=np.var(np.array(Fear))\n","            var_Happy=np.var(np.array(Happy))\n","            var_Sad=np.var(np.array(Sad))\n","            var_Surprise=np.var(np.array(Surprise))\n","            var_Neutral=np.var(np.array(Neutral))\n","\n","            list_to_append=[mean_Anger,var_Anger,mean_Disgust,var_Disgust,mean_Fear,var_Fear,mean_Happy,var_Happy,mean_Sad,var_Sad,mean_Surprise,var_Surprise,mean_Neutral,var_Neutral,np.mean(np.array(colors_R)),np.var(np.array(colors_R)),np.mean(np.array(colors_G)),np.var(np.array(colors_G)),np.mean(np.array(colors_B)),np.var(np.array(colors_B)),np.mean(np.array(brightness)),np.mean(np.var(brightness)),video_fps,width,height,duration]\n","            #df=df.append(pd.Series(list_to_append,index=[\"IMDB_ID\",\"mean_Anger\",\"var_Anger\",\"mean_Disgust\",\"var_Disgust\",\"mean_Fear\",\"var_Fear\",\"mean_Happy\",\"var_Happy\",\"mean_Sad\",\"var_Sad\",\"mean_Surprise\",\"var_Surprise\",\"mean_Neutral\",\"var_Neutral\",\"R_mean\",\"R_var\",\"G_mean\",\"G_var\",\"B_mean\",\"B_var\",\"Brightness_mean\",\"Brightness_var\",\"Sharpness_mean\",\"Sharpness_var\"]),ignore_index=True)\n","        \n","        else:\n","             list_to_append=[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","        return list_to_append\n","                                                                                                                                                                                                                                                      \n","\n","    # ****** iteration over all movies ****** \"\"\"\n","    def run(self, movies, trailers_dir, resolution, output_path, output_file):\n","\n","        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        features_name = [\"IMDB_ID\",\"mean_Anger\",\"var_Anger\",\"mean_Disgust\",\"var_Disgust\",\"mean_Fear\",\"var_Fear\",\"mean_Happy\",\"var_Happy\",\"mean_Sad\",\"var_Sad\",\"mean_Surprise\",\"var_Surprise\",\"mean_Neutral\",\"var_Neutral\",\"R_mean\",\"R_var\",\"G_mean\",\"G_var\",\"B_mean\",\"B_var\",\"Brightness_mean\",\"Brightness_var\",\"video_fps\",\"width\",\"height\",\"duration\"]\n","        #df =pd.DataFrame(columns=features_name)\n","        '''with open('Akram.csv', 'w+') as fp:\n","            wr = csv.writer(fp)\n","            wr.writerow(features_name)'''\n","            \n","        #iterate over videos\n","        movies_to_iterate = movies.entries[6000+20:7000]\n","        pbar1 = tqdm_notebook(total=len(movies_to_iterate))\n","        \n","        for id, entry in enumerate(movies_to_iterate):# start:end\n","            # Store sample\n","            videoFile = os.path.join(trailers_dir, entry.movie_id +'.mp4')\n","            print('Retrieving movie ', entry.movie_id, 'id:', id)\n","            #print('Retrieving movie ', entry.movie_id)\n","            broken = False\n","            if not os.path.isfile(videoFile):\n","                print('Donwload trailer')\n","                movies.GetTrailer(entry.imdb_trailer, entry.youtube_trailer, trailers_dir, entry.movie_id)\n","                #time.sleep(5)\n","                timer = time.time()\n","                while not os.path.isfile(videoFile):\n","                    #print('Trailer is not yet ready')\n","                    time.sleep(1)\n","                    if(time.time() - timer > 20):\n","                        broken = True\n","                        break\n","            if broken:\n","                continue\n","            \"\"\"if not os.path.isfile(videoFile):\n","                print('Donwload trailer', id)\n","                print(entry.youtube_trailer)\n","                movies.GetTrailer(entry.imdb_trailer, entry.youtube_trailer, trailers_dir, entry.movie_id)\n","                \n","            while not os.path.isfile(videoFile):\n","                #print('Trailer is not yet ready')\n","                time.sleep(1)\"\"\"\n","            print('Start extracting visual features')\n","            # video to frames and append to colors list\n","            list_to_append=[entry.movie_id, ] + self.extract(os.path.join(trailers_dir, entry.movie_id+'.mp4'), resolution)\n","            #df=df.append(pd.Series(list_to_append,index=features_name),ignore_index=True)\n","            with open(os.path.join(output_path,output_file), 'a',newline='') as f:\n","                wr = csv.writer(f)\n","                wr.writerow(list_to_append)\n","            print('Extracting features done!')\n","            #delete video\n","            file_to_remove = os.path.join(trailers_dir, entry.movie_id+'.mp4')\n","            !rm -r $file_to_remove > /dev/null\n","            !rm -rf ~/.local/share/Trash/*\n","            #!rm -r output_path+entry.movie_id+'.mp4\n","            #!rm -r to_remove\n","            pbar1.update(1)\n","\n","        #df.to_csv(os.path.join(output_path, output_file), sep=',')\n","        print(\"Sucess, Completed\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QPBbhTasHWAV","colab_type":"code","colab":{}},"source":["visual_feature_extractor = VisualFeatureExtractor(model_dir = '../trained_model')\n","visual_feature_extractor.run(movies = movies, trailers_dir = \"./\", resolution = (640, 480), output_path = \"./\", output_file =\"visual_features.csv\")"],"execution_count":0,"outputs":[]}]}